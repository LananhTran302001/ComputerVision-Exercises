{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SURF descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The SURF algorithm is based on the same principles and steps as SIFT; but details in each step are different. <br>\n",
    "The algorithm is composed of 2 main parts:<br>\n",
    "Part 1: interest point detection<br>\n",
    "Part 2: local neighborhood description<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><strong>1. Interesting point detection</strong><br>\n",
    "\n",
    "1.1. Fast-Hessian Detector<br><br>\n",
    "SURF uses the Hessian matrix because of its good performance in computation time and accuracy. Rather than using a <br>\n",
    "different measure for selecting the location and the scale (Hessian-Laplace detector). Given a point x = (x, y) in an <br>\n",
    "image I, the Hessian matrix H(x, σ) in x at scale σ is defined as follows: <br><br>\n",
    "\\begin{equation*}\n",
    "H(x, \\sigma) = \n",
    "\\begin{bmatrix}\n",
    "L_{xx}(x, \\sigma) & L_{xy}(x, \\sigma) \\\\\n",
    "L_{xy}(x, \\sigma) & L_{yy}(x, \\sigma)\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{align*} \n",
    "L_{xx}(x, \\sigma) \n",
    "\\end{align*}\n",
    "is the convolution of the Gaussian second order derivative: \n",
    "\\begin{align*} \n",
    "\\frac{d^2}{dx^x} G(\\sigma) \\text{ with the image I in point x }\n",
    "\\end{align*}\n",
    "\n",
    "In order to calculate the determinant of the Hessian matrix, first we need to apply convolution with Gaussian kernel, then <br>\n",
    "second-order derivative. In SIFT, Lowe approximated Laplacian of Gaussian with Difference of Gaussian for finding scale-space. <br>\n",
    "SURF goes a little further and approximates LoG with Box Filter. Below image shows a demonstration of such an approximation:<br><br>\n",
    "<img src=\"surf_boxfilter.jpg\"><br><br>\n",
    "The crude approximations are valuable because they can be very quickly run at any scale due to the use of an integral image.<br><br>\n",
    "<img src=\"masks.jpg\"><br>\n",
    "<small>Approximated Gaussian second derivative in y-direction and xy-direction, used for the SURF detector.</small><br><br><br>\n",
    "\n",
    "1.2. Scale-space representation<br><br>\n",
    "Scale spaces are usually implemented as image pyramids. The images are repeatedly smoothed with a Gaussian and subsequently <br>\n",
    "sub-sampled in order to achieve a higher level of the pyramid. Due to the use of box filters and integral images, SURF does not <br>\n",
    "have to iteratively apply the same filter to the output of a previously filtered layer, but instead can apply such filters of any <br>\n",
    "size at exactly the same speed directly on the original image, and even in parallel (although the latter is not exploited here).<br> \n",
    "Therefore, the scale space is analysed by up-scaling the filter size rather than iteratively reducing the image size. Besides, <br>\n",
    "each kernel need to have an uneven size to have a central pixel. This results in filters of size 9×9, 15×15, 21×21, 27×27, etc..<br>\n",
    "With this step, extremas can be found out, and they are detected as points of interests.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><strong>2. Local neighborhood description</strong><br>\n",
    "\n",
    "The SURF descriptor is designed to be scale invariant and rotationally invariant.<br>\n",
    "To ignore scale the descriptor is sampled over a window that is proportional to the window size with which it was detected, <br>\n",
    "that way if a scaled version of the feature is in another image the descriptor for that feature will be sampled over the same <br>\n",
    "relative area.<br>\n",
    "\n",
    "Rotation is handled by finding the dominant direction of the feature and rotating the sampling window to align with that angle.<br>\n",
    "Once the rotated neighborhood is obtained it is divided up into 16 subsquares, each sub square is again divided into 4 <br>\n",
    "squares. Derivatives in the x and y directions are taken in these final squares. The descriptor for the sub square is the sum <br>\n",
    "of the x derivatives over its four quadrants, sum of the absolute values of the x derivatives and similarly for y. The total <br>\n",
    "descriptor is 4 values per subsquare for a total of 64 values. This vector is normalized to length 1 and is the feature descriptor.<br>\n",
    "<br><img src=\"surf_descriptor.jpg\"><br>\n",
    "<small>A graphical representation of the SURF descriptor. This figure taken from the original SURF paper.</small><br><br>\n",
    "This 16x4 descriptor is a 64 dimensional one, and SURF also supports an extended 128 dimensional descriptor, for cases <br>\n",
    "requiring a higher distinctiveness in its features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV SURF\n",
    "OpenCV provides SURF functionalities just like SIFT. We can use SURF.detect(), SURF.compute() etc for finding keypoints and descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_SURF_descriptor(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Applying SURF detector\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    kp, des = surf.detectAndCompute(gray_img, None)\n",
    "    print(\"Number of keypoints: \", len(kp))\n",
    "    print (\"Keypoint description:\")\n",
    "    for p in des:\n",
    "        print(p)\n",
    "\n",
    "    # Marking the keypoint on the image using circles\n",
    "    img=cv2.drawKeypoints(gray_img ,\n",
    "                            kp ,\n",
    "                            img ,\n",
    "                            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../hanoi.jpg\")\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_SURF_descriptor(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Sources:</u><br><br>\n",
    "https://people.ee.ethz.ch/~surf/eccv06.pdf<br><br>\n",
    "https://medium.com/data-breach/introduction-to-surf-speeded-up-robust-features-c7396d6e7c4e <br><br>\n",
    "https://docs.opencv.org/3.4/df/dd2/tutorial_py_surf_intro.html <br><br>\n",
    "https://courses.cs.washington.edu/courses/cse576/13sp/projects/project1/artifacts/woodrc/index.htm <br><br>\n",
    "https://zhvillues.tumblr.com/post/119561114181/sift-vs-surf <br><br>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
